{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Efficient Legal Summarization: Harnessing Transformers for Terms and Conditions**"
      ],
      "metadata": {
        "id": "bY3_l_e4zTBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Team Members:**\n",
        "\n",
        "#### - **Shravan Venkatraman 21BCE1200**\n",
        "#### - **Pavan Kumar S 21BCE1179**\n",
        "#### - **Ayush Kumar Lal 21BCE1129**"
      ],
      "metadata": {
        "id": "BHkvam-MzYTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Abstract**\n",
        "\n",
        "Legal terms and conditions are often **complex and lengthy**, making them **difficult to understand**. Manually summarizing these documents would be **time-consuming** and **susceptible to errors**, which might lead to **severe issues** in the future.\n",
        "\n",
        "To tackle this problem, we propose a **novel** encoder-decoder based **NLP transformer architecture** to **automate** the summarization process.\n",
        "\n",
        "These embeddings are then processed by our **Transformer-based model**, which uses an **Adaptive Multi-Head Attention (MHA)** mechanism to generate a **concise summary** of the input document.\n",
        "\n",
        "This approach aims to **improve accessibility** and **comprehension** of legal documents, offering a **more efficient and error-free solution**.\n"
      ],
      "metadata": {
        "id": "HBtJYFsjzxV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Setup and Imports**"
      ],
      "metadata": {
        "id": "uK0mcJqLyafM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers==4.31.0 torch pypdf2"
      ],
      "metadata": {
        "id": "e-sKEdq-j5rd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BartTokenizer, BartConfig\n",
        "from transformers.models.bart.modeling_bart import (\n",
        "    BartForConditionalGeneration,\n",
        "    BartEncoder,\n",
        "    BartDecoder,\n",
        "    BartAttention,\n",
        "    BartEncoderLayer,\n",
        "    BartDecoderLayer,\n",
        ")\n",
        "import PyPDF2\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n"
      ],
      "metadata": {
        "id": "XJSjWsVVj5ps"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Define the Adaptive Multi-Head Attention (AMHA)**"
      ],
      "metadata": {
        "id": "KyDgkstOyk9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptiveMultiHeadAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, dropout=0.0, is_decoder=False):\n",
        "        super(AdaptiveMultiHeadAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads  # Initial number of heads\n",
        "        self.max_heads = num_heads  # Set max_heads to num_heads for compatibility\n",
        "        self.head_dim = embed_dim // self.max_heads\n",
        "        assert (\n",
        "            self.head_dim * self.max_heads == self.embed_dim\n",
        "        ), \"embed_dim must be divisible by max_heads\"\n",
        "\n",
        "        self.scaling = self.head_dim ** -0.5\n",
        "\n",
        "        self.is_decoder = is_decoder\n",
        "        self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "        # Adaptive parameters\n",
        "        self.head_selector = nn.Linear(embed_dim, self.max_heads)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        key_value_states=None,\n",
        "        past_key_value=None,\n",
        "        attention_mask=None,\n",
        "        layer_head_mask=None,\n",
        "        output_attentions=False,\n",
        "    ):\n",
        "        \"\"\"Input shape: Batch x Time x Channel\"\"\"\n",
        "\n",
        "        is_cross_attention = key_value_states is not None\n",
        "\n",
        "        # Adaptive head selection\n",
        "        head_scores = self.head_selector(hidden_states).mean(dim=1)  # [Batch, max_heads]\n",
        "        head_probs = torch.softmax(head_scores, dim=-1)\n",
        "        active_heads = (head_probs > (1 / self.max_heads)).sum().item()\n",
        "        num_heads = max(1, min(active_heads, self.max_heads))\n",
        "\n",
        "        # Project queries, keys, and values\n",
        "        query_states = self.q_proj(hidden_states) * self.scaling\n",
        "\n",
        "        if is_cross_attention:\n",
        "            if past_key_value is not None:\n",
        "                key_states = past_key_value[0]\n",
        "                value_states = past_key_value[1]\n",
        "            else:\n",
        "                key_states = self.k_proj(key_value_states)\n",
        "                value_states = self.v_proj(key_value_states)\n",
        "                if self.is_decoder:\n",
        "                    # If caching is enabled, set up past key value states\n",
        "                    past_key_value = (key_states, value_states)\n",
        "        else:\n",
        "            key_states = self.k_proj(hidden_states)\n",
        "            value_states = self.v_proj(hidden_states)\n",
        "            if self.is_decoder and past_key_value is not None:\n",
        "                # Append to past key value states for caching\n",
        "                key_states = torch.cat([past_key_value[0], key_states], dim=1)\n",
        "                value_states = torch.cat([past_key_value[1], value_states], dim=1)\n",
        "                past_key_value = (key_states, value_states)\n",
        "            elif self.is_decoder:\n",
        "                past_key_value = (key_states, value_states)\n",
        "\n",
        "        # Reshape to [Batch, Time, Num_heads, Head_dim]\n",
        "        query_states = query_states.view(\n",
        "            hidden_states.size(0), -1, self.max_heads, self.head_dim\n",
        "        )[:, :, :num_heads, :]\n",
        "        key_states = key_states.view(\n",
        "            hidden_states.size(0), -1, self.max_heads, self.head_dim\n",
        "        )[:, :, :num_heads, :]\n",
        "        value_states = value_states.view(\n",
        "            hidden_states.size(0), -1, self.max_heads, self.head_dim\n",
        "        )[:, :, :num_heads, :]\n",
        "\n",
        "        # Transpose for attention calculation\n",
        "        query_states = query_states.transpose(1, 2)  # [Batch, Num_heads, Time, Head_dim]\n",
        "        key_states = key_states.transpose(1, 2)\n",
        "        value_states = value_states.transpose(1, 2)\n",
        "\n",
        "        # Compute attention scores\n",
        "        attn_weights = torch.matmul(query_states, key_states.transpose(-1, -2))\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attn_weights += attention_mask\n",
        "\n",
        "        attn_weights = torch.softmax(attn_weights, dim=-1)\n",
        "\n",
        "        if layer_head_mask is not None:\n",
        "            attn_weights = attn_weights * layer_head_mask.view(1, -1, 1, 1)\n",
        "\n",
        "        attn_probs = self.dropout(attn_weights)\n",
        "\n",
        "        # Apply attention to values\n",
        "        attn_output = torch.matmul(attn_probs, value_states)\n",
        "\n",
        "        # Transpose and reshape to [Batch, Time, Num_heads * Head_dim]\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous()\n",
        "        attn_output = attn_output.view(\n",
        "            hidden_states.size(0), -1, num_heads * self.head_dim\n",
        "        )\n",
        "\n",
        "        # Pad or truncate attn_output to match embed_dim\n",
        "        if attn_output.size(-1) < self.embed_dim:\n",
        "            padding = attn_output.new_zeros(\n",
        "                attn_output.size(0), attn_output.size(1), self.embed_dim - attn_output.size(-1)\n",
        "            )\n",
        "            attn_output = torch.cat([attn_output, padding], dim=-1)\n",
        "        elif attn_output.size(-1) > self.embed_dim:\n",
        "            attn_output = attn_output[:, :, : self.embed_dim]\n",
        "\n",
        "        attn_output = self.out_proj(attn_output)\n",
        "\n",
        "        outputs = (attn_output,)\n",
        "\n",
        "        if output_attentions:\n",
        "            outputs += (attn_weights,)\n",
        "        else:\n",
        "            outputs += (None,)\n",
        "\n",
        "        outputs += (past_key_value,)\n",
        "\n",
        "        return outputs  # attn_output, attn_weights (or None), past_key_value\n"
      ],
      "metadata": {
        "id": "fvLsFqJ5j5nx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Create Custom Encoder and Decoder Layers**"
      ],
      "metadata": {
        "id": "uvTSWsTfyoYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.1 Custom Encoder Layer**"
      ],
      "metadata": {
        "id": "qjrhh9H0yukO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBartEncoderLayer(BartEncoderLayer):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.self_attn = AdaptiveMultiHeadAttention(\n",
        "            embed_dim=config.d_model,\n",
        "            num_heads=config.encoder_attention_heads,\n",
        "            dropout=config.attention_dropout,\n",
        "            is_decoder=False,\n",
        "        )\n",
        "        # Re-initialize the layer norm to match dimensions\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(config.d_model)\n"
      ],
      "metadata": {
        "id": "h63XIxkej5ld"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2 Custom Decoder Layer**"
      ],
      "metadata": {
        "id": "MLKhtu-ayzAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBartDecoderLayer(BartDecoderLayer):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.self_attn = AdaptiveMultiHeadAttention(\n",
        "            embed_dim=config.d_model,\n",
        "            num_heads=config.decoder_attention_heads,\n",
        "            dropout=config.attention_dropout,\n",
        "            is_decoder=True,\n",
        "        )\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(config.d_model)\n",
        "\n",
        "        self.encoder_attn = AdaptiveMultiHeadAttention(\n",
        "            embed_dim=config.d_model,\n",
        "            num_heads=config.decoder_attention_heads,\n",
        "            dropout=config.attention_dropout,\n",
        "            is_decoder=True,\n",
        "        )\n",
        "        self.encoder_attn_layer_norm = nn.LayerNorm(config.d_model)\n"
      ],
      "metadata": {
        "id": "HzYc_Xwbj5jM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Create Custom Encoder and Decoder**"
      ],
      "metadata": {
        "id": "sLDmPaLDy18K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.1 Custom Encoder**"
      ],
      "metadata": {
        "id": "hMGDiW4py4BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBartEncoder(BartEncoder):\n",
        "    def __init__(self, config, embed_tokens):\n",
        "        super().__init__(config, embed_tokens)\n",
        "        self.layers = nn.ModuleList(\n",
        "            [CustomBartEncoderLayer(config) for _ in range(config.encoder_layers)]\n",
        "        )\n"
      ],
      "metadata": {
        "id": "Bw5eut20j5g-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.2 Custom Decoder**"
      ],
      "metadata": {
        "id": "pDZWieKey6VZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBartDecoder(BartDecoder):\n",
        "    def __init__(self, config, embed_tokens):\n",
        "        super().__init__(config, embed_tokens)\n",
        "        self.layers = nn.ModuleList(\n",
        "            [CustomBartDecoderLayer(config) for _ in range(config.decoder_layers)]\n",
        "        )\n"
      ],
      "metadata": {
        "id": "XB5-UqWpj5eu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Create the Custom BART Model**"
      ],
      "metadata": {
        "id": "a8PBOvqny862"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBartModel(BartForConditionalGeneration):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.model.encoder = CustomBartEncoder(config, self.model.shared)\n",
        "        self.model.decoder = CustomBartDecoder(config, self.model.shared)\n"
      ],
      "metadata": {
        "id": "4Fbsrd24j5cb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Load Pre-trained Weights**"
      ],
      "metadata": {
        "id": "x8V--zNoy_Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pretrained_weights(custom_model, pretrained_model_name):\n",
        "    # Load the state dict of the pre-trained model\n",
        "    pretrained_model = BartForConditionalGeneration.from_pretrained(pretrained_model_name)\n",
        "    pretrained_state_dict = pretrained_model.state_dict()\n",
        "\n",
        "    custom_state_dict = custom_model.state_dict()\n",
        "\n",
        "    # Filter out attention layers from the state dict\n",
        "    filtered_state_dict = {}\n",
        "    for name, param in pretrained_state_dict.items():\n",
        "        if \"self_attn\" not in name and \"encoder_attn\" not in name:\n",
        "            filtered_state_dict[name] = param\n",
        "\n",
        "    # Load the filtered state dict into the custom model\n",
        "    custom_model.load_state_dict(filtered_state_dict, strict=False)\n",
        "\n",
        "    # The modified attention layers are re-initialized\n",
        "    return custom_model\n"
      ],
      "metadata": {
        "id": "x4B1O4nAj5aJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Training and Inference**"
      ],
      "metadata": {
        "id": "cTre0tydzCxw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.1 Initialize Tokenizer and Model**"
      ],
      "metadata": {
        "id": "TekU6KX6zDsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "config = BartConfig.from_pretrained('facebook/bart-base')\n",
        "custom_model = CustomBartModel(config)\n",
        "custom_model = load_pretrained_weights(custom_model, 'facebook/bart-base')\n",
        "custom_model = custom_model.to('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8taj-Onj5X7",
        "outputId": "fe81eb78-4a27-499b-f8ec-9e30dcd52d01"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.2 Prepare Data**"
      ],
      "metadata": {
        "id": "ROK1c-sxzG1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_pdfs_from_directory(directory_path):\n",
        "    documents = []\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.endswith('.pdf'):\n",
        "          print(filename)\n",
        "\n",
        "pdf_directory = '/content'\n",
        "show_pdfs_from_directory(pdf_directory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8fMNFObrQDV",
        "outputId": "f1e90529-31b7-4cc7-bc8e-035d3679dd26"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Airbnb.pdf\n",
            "SaaS.pdf\n",
            "HealthApp.pdf\n",
            "CloudStorage.pdf\n",
            "EducationalPlatforms.pdf\n",
            "GamingPlatforms.pdf\n",
            "ecommerceapp.pdf\n",
            "socialmediaplatform.pdf\n",
            "netbankingapp.pdf\n",
            "fooddeliveryapp.pdf\n",
            "streamingservice.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def read_pdf(file_path):\n",
        "    pdf_reader = PyPDF2.PdfReader(file_path)\n",
        "    text = \"\"\n",
        "    for page in pdf_reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def read_pdfs_from_directory(directory_path):\n",
        "    documents = []\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.endswith('.pdf'):\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "            text = read_pdf(file_path)\n",
        "            documents.append(text)\n",
        "    return documents\n",
        "\n",
        "documents = read_pdfs_from_directory(pdf_directory)\n",
        "\n",
        "summaries = [\n",
        "    \"\"\"\n",
        "    These terms cover the use of the online booking platform, requiring users to create an account and follow the Platform's conduct guidelines. Booking payments are processed through the Platform, and cancellation policies may vary. Users retain ownership of their content but grant the Platform rights to use it. Hosts are responsible for listing accuracy and guest safety, while guests must respect property and house rules. The Platform disclaims warranties, limits liability for damages, and collects user data per its Privacy Policy. Disputes are resolved through arbitration, and the terms may be updated periodically.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    These terms govern the use of the SaaS platform, requiring users to register an account and follow usage guidelines. Users must not engage in illegal activities, interfere with the platform's functionality, or misuse services. The Platform grants users a limited license to access its services, while user-generated content remains the user's property. Paid subscriptions may be required for certain features, and fees may change. The platform disclaims warranties and limits liability for damages. Data collection and use comply with the Privacy Policy, but absolute security is not guaranteed. The terms may change, and users agree to resolve disputes through arbitration.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    The HealthTrack app requires users to agree to its Terms and Conditions, which include accepting all legal obligations. Users must be at least 18 or have parental consent to access the app. HealthTrack reserves the right to modify these terms at any time, and users are responsible for reviewing them regularly. The app is intended for health tracking purposes only and is not a substitute for professional medical advice. Users are accountable for their account security and for complying with legal requirements when sharing content. The app offers both free and paid subscription options, with auto-renewal for paid services unless canceled. HealthTrack takes data privacy seriously but acknowledges that no method is entirely secure. The content within the app is owned by HealthTrack and cannot be modified or sold without permission. The app also integrates with third-party services but is not responsible for their actions. HealthTrack provides its services \"as is\" without any guarantees of uninterrupted service or freedom from errors, and its liability is limited to the amount paid by the user. Users' access may be terminated for any violations of the Terms. Legal disputes are subject to the laws of the app's jurisdiction and resolved through arbitration. Finally, if any part of these Terms is deemed invalid, the remainder will still apply.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    These terms govern the use of the cloud storage service, requiring users to create an account and follow the Service's guidelines. Users are responsible for their account security and agree not to engage in prohibited activities. Uploaded content remains the user's property, but users grant the Service a license to manage it as needed. The Service collects and uses personal data per its Privacy Policy, and security measures are in place, though absolute security is not guaranteed. Fees may apply for certain features, and prices can change. The Service disclaims warranties and limits its liability for damages. Terms may be amended, and user accounts can be terminated for violations. Disputes will be resolved through arbitration, and the terms are governed by the laws of the specified jurisdiction.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    These terms govern the use of the Platform and require users to register for an account. Users are responsible for their actions and must comply with the Platform's guidelines. Content shared on the Platform remains the user’s property, but users grant the Platform a license to use it. Courses may require payment, and refunds are limited. The Platform limits liability and disclaims warranties regarding content accuracy. Personal data is handled according to the Privacy Policy. Terms may change, and continued use signifies acceptance of new terms. Violations may result in termination, and disputes are subject to arbitration under applicable law.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    These terms govern the use of the gaming platform, requiring users to create an account and adhere to conduct guidelines, which prohibit cheating, illegal activities, and harassment. Users can purchase games, DLC, and other digital content, but only receive a license to use, not own, the content. Subscription services may be available, and refunds are governed by a specific policy. The Platform disclaims warranties and limits liability for damages. Modifications to content, terms, and services may occur at any time. Disputes are resolved through arbitration, and the terms are governed by the laws of the specified jurisdiction.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    By using flipkart.com, you agree to the terms outlined here. These terms include the process for creating an account, placing orders, and making payments. Prices are subject to change, and once an order is confirmed, you will receive a notification via email. Products are shipped based on availability, and estimated delivery times may vary. Our returns policy allows you to return items within 7 days in their original condition, and refunds will be processed promptly. The website's content is protected by intellectual property laws, and you must not copy or misuse it. Users are expected to act responsibly when using our services, and accounts can be suspended for fraudulent or harmful behavior. Your personal data is protected under our Privacy Policy. These terms may be updated from time to time, and any legal matters will be handled according to the laws of Constitution of the Republic of India. If you have any questions, please reach out to our support team.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    By using ConnectSphere, you agree to create an account with accurate information and are responsible for maintaining the security of your login details. Users own the content they post but grant ConnectSphere a license to display and use the content within the platform. Harmful or illegal behavior, including harassment, spam, and impersonation, is prohibited, and such actions may result in account suspension or termination. ConnectSphere takes privacy seriously and follows data protection standards, with user data managed according to the Privacy Policy. While users can interact with third-party links on the platform, ConnectSphere is not responsible for the content or security of those third-party services. Users may deactivate their accounts at any time, but ConnectSphere reserves the right to moderate content and terminate accounts that violate the platform's terms. Disputes are governed by the laws of the United States, with any legal matters handled in California courts. For more information or assistance, users can contact ConnectSphere’s support team.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    By using the EasyBank app, you agree to these Terms and Conditions. You must create an account with accurate information and are responsible for maintaining the security of your login credentials. EasyBank provides a range of banking services, including account management, fund transfers, bill payments, and mobile deposits. Users must have sufficient funds to complete transactions, and certain services may incur fees. EasyBank prioritizes account security, and users are required to use two-factor authentication. You should immediately report any suspicious activity. Transactions may be subject to verification and are not guaranteed until confirmed. If your account is found to have violated these terms, it may be suspended or terminated. EasyBank collects and uses your personal and financial data in accordance with its Privacy Policy. For any disputes, users agree to resolve them through binding arbitration in California.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    By using the QuickBite app, you agree to create an account with accurate information and are responsible for keeping your login details secure. You will be charged the total amount displayed for your order, including any taxes, fees, and tips, with payments handled through third-party processors. Cancellations and refunds are only available within limited timeframes and are subject to restaurant policies. Delivery times are estimates, and QuickBite cannot guarantee exact delivery times due to external factors like traffic and weather. You must provide accurate delivery information and behave respectfully towards delivery partners and restaurant staff. QuickBite collects and processes your data in accordance with its Privacy Policy. If you violate any terms or engage in fraudulent activity, QuickBite reserves the right to suspend or terminate your account. All disputes are governed by the laws of Illinois, with arbitration in Chicago if needed. For further questions, users can contact QuickBite's support team.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    By using StreamFlix, you agree to create an account with accurate information and are responsible for keeping your login details secure. Your subscription will automatically renew unless you cancel it before the renewal date. StreamFlix offers various subscription plans, and content availability may vary based on your location. You must not engage in illegal activities or attempt to redistribute or copy content from the platform. Your use of StreamFlix is for personal, non-commercial purposes only, and we may suspend or terminate your account if you violate these terms. StreamFlix strives to provide a high-quality streaming experience, but the quality may vary based on your internet connection. StreamFlix is not responsible for interruptions or errors in the service. For any issues, you can contact our support team. Disputes will be governed by the laws of New York, and users agree to resolve disputes through the courts in New York City.\n",
        "    \"\"\",\n",
        "    # Add summaries corresponding to each document\n",
        "]\n",
        "\n",
        "assert len(documents) == len(summaries), \"Number of documents and summaries must be equal.\"\n",
        "print(\"Assertion tests passed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8RoojFxkiVu",
        "outputId": "e4b05ea4-732f-4771-bd21-667ab0e7ea24"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assertion tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.3 Create Dataset and DataLoader**"
      ],
      "metadata": {
        "id": "_pqAPsuZzJXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and encode the data\n",
        "def encode_data(documents, summaries, tokenizer, max_length=512):\n",
        "    inputs = tokenizer(\n",
        "        documents,\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt',\n",
        "    )\n",
        "    targets = tokenizer(\n",
        "        summaries,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt',\n",
        "    )\n",
        "    return inputs, targets\n",
        "\n",
        "inputs, targets = encode_data(documents, summaries, tokenizer)\n"
      ],
      "metadata": {
        "id": "9mO-wC95j5Vx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class LegalSummarizationDataset(Dataset):\n",
        "    def __init__(self, inputs, targets):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.inputs.input_ids.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            'input_ids': self.inputs.input_ids[idx],\n",
        "            'attention_mask': self.inputs.attention_mask[idx],\n",
        "            'labels': self.targets.input_ids[idx],\n",
        "        }\n",
        "        return item\n",
        "\n",
        "dataset = LegalSummarizationDataset(inputs, targets)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "YAQNKfrYj5Tq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.4 Define Training Loop**"
      ],
      "metadata": {
        "id": "MZtv3tfPzLwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(custom_model.parameters(), lr=5e-5)\n",
        "num_epochs = 128\n",
        "total_steps = len(dataloader) * num_epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "custom_model.train()\n",
        "print(\"Training Transformer Model with Adaptive Multi Head Attention\")\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = custom_model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "    if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrM5-F1xj5Rn",
        "outputId": "2468d349-4d88-4705-e610-717c6ec4949f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Transformer Model with Adaptive Multi Head Attention\n",
            "Epoch 1/128, Loss: 11.6949\n",
            "Epoch 11/128, Loss: 3.8078\n",
            "Epoch 21/128, Loss: 2.3730\n",
            "Epoch 31/128, Loss: 1.8377\n",
            "Epoch 41/128, Loss: 1.5218\n",
            "Epoch 51/128, Loss: 1.4199\n",
            "Epoch 61/128, Loss: 1.2575\n",
            "Epoch 71/128, Loss: 1.1723\n",
            "Epoch 81/128, Loss: 1.0435\n",
            "Epoch 91/128, Loss: 0.9782\n",
            "Epoch 101/128, Loss: 0.9427\n",
            "Epoch 111/128, Loss: 0.8920\n",
            "Epoch 121/128, Loss: 0.8374\n",
            "Epoch 128/128, Loss: 0.8427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.5 Inference**"
      ],
      "metadata": {
        "id": "UVCSr0hfzNvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model.eval()\n",
        "\n",
        "def summarize(text, max_length=128):\n",
        "    inputs = tokenizer(\n",
        "        [text],\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt',\n",
        "    )\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        summary_ids = custom_model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=max_length,\n",
        "            num_beams=4,\n",
        "            early_stopping=True,\n",
        "        )\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Example usage\n",
        "test_document = \"\"\"The HealthTrack app requires users to agree to its Terms and Conditions, which include accepting all legal obligations. Users must be at least 18 or have parental consent to access the app. HealthTrack reserves the right to modify these terms at any time, and users are responsible for reviewing them regularly. The app is intended for health tracking purposes only and is not a substitute for professional medical advice. Users are accountable for their account security and for complying with legal requirements when sharing content. The app offers both free and paid subscription options, with auto-renewal for paid services unless canceled. HealthTrack takes data privacy seriously but acknowledges that no method is entirely secure. The content within the app is owned by HealthTrack and cannot be modified or sold without permission. The app also integrates with third-party services but is not responsible for their actions. HealthTrack provides its services \"as is\" without any guarantees of uninterrupted service or freedom from errors, and its liability is limited to the amount paid by the user. Users' access may be terminated for any violations of the Terms. Legal disputes are subject to the laws of the app's jurisdiction and resolved through arbitration. Finally, if any part of these Terms is deemed invalid, the remainder will still apply.\"\"\"\n",
        "generated_summary = summarize(test_document)\n",
        "print(\"Generated Summary:\", generated_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnVPoJSfj5Pd",
        "outputId": "fe088db2-ccf2-457b-cb80-b516f83a8d96"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary:  Users must be at least 18 or have parental consent to access the right to modify these terms at any time, which include accepting all legal obligations. The app offers both free and for professional medical advice. HealthTrack takes data privacy seriously\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nRSGdJ1SzPiy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}